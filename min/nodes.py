# nodes.py
"""
LangGraph-based AI Wedding Planner Agent - Node Functions
=========================================================

This module contains all the node functions for the wedding planner AI agent.
Each node represents a specific processing step in the conversation flow.

Node Categories:
- Core Processing Nodes: parsing, memo_check, conditional_router
- Specialized Action Nodes: recommendation, tool_execution, memo_update  
- Response Generation Nodes: response_generation
- Error Handling Nodes: error_handler

All nodes follow the standard LangGraph pattern:
- Input: state (Dict) containing current conversation state
- Output: updated state (Dict) with processing results
- Error handling: sets state['status'] = 'error' and state['reason'] on failures
"""

import os
import json
import re
import traceback
from datetime import datetime
from typing import List, Dict, Any, Optional, Union
from tools import web_search_tool, calculator_tool, db_query_tool, user_db_update_tool


from openai import OpenAI
from dotenv import load_dotenv

# Project modules
from state import (
    State, create_empty_user_memo, get_memo_file_path, 
    touch_processing_timestamp, memo_set_budget, memo_set_wedding_date, memo_set_guest_count
)
from db import db
from tools import TOOL_REGISTRY

# LLM client initialization
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ============= SYSTEM PROMPTS (Separated for maintainability) =============

PARSING_SYSTEM_PROMPT = """You are a wedding planning assistant specializing in Korean wedding culture. 
Your primary task is to analyze user input and extract structured information for routing decisions.

Extract the following information from user input:

1. VENDOR_TYPE: Identify wedding service categories
   - wedding_hall: Wedding venues and reception halls
   - studio: Photography and videography studios  
   - wedding_dress: Bridal wear and dress shops
   - makeup: Beauty and makeup services
   - null: No specific vendor type mentioned

2. REGION: Korean location keywords  
   - Major areas: ê°•ë‚¨, ì²­ë‹´, ì••êµ¬ì •, í™ëŒ€, ëª…ë™, ì ì‹¤, ì—¬ì˜ë„, etc.
   - null: No location preference specified

3. INTENT_HINT: Classify user's primary intention
   - "recommend": User seeking venue/vendor recommendations
   - "tool": Requests requiring database updates, calculations, or searches
   - "general": General consultation, advice, or information requests

4. UPDATE_TYPE: Profile update requests (for tool routing)
   - "wedding_date": Date changes or scheduling
   - "budget": Budget modifications or financial planning  
   - "guest_count": Guest list size changes
   - "preferred_location": Location preference updates
   - null: No profile updates needed

5. BUDGET_MANWON: Extract budget information in Korean "ë§Œì›" units
   - Convert various Korean expressions to integer values
   - Examples: "5ì²œë§Œì›" â†’ 5000, "2ì–µ" â†’ 20000, "300ë§Œì›" â†’ 300
   - null: No budget information provided

6. CONFIDENCE: Your confidence in the extraction (0.0-1.0)

Respond in JSON format:
{
    "vendor_type": "wedding_hall|studio|wedding_dress|makeup|null",
    "region": "ê°•ë‚¨|ì²­ë‹´|etc.|null", 
    "intent_hint": "recommend|tool|general",
    "update_type": "wedding_date|budget|guest_count|preferred_location|null",
    "budget_manwon": 5000,
    "confidence": 0.85
}"""

RESPONSE_GENERATION_SYSTEM_PROMPT = """You are a professional Korean wedding planner AI assistant.
Generate helpful, personalized responses based on the conversation context and tool results.

Guidelines:
1. Use a warm, professional tone appropriate for wedding planning
2. Incorporate user's specific information (budget, date, preferences) when available
3. Provide actionable advice and clear next steps
4. Include relevant suggestions for follow-up questions
5. Keep responses concise but comprehensive
6. Use Korean cultural context for wedding traditions and customs

Context Integration:
- Tool results: Incorporate database query results, calculations, and web search findings
- User memory: Reference previous conversations and established preferences  
- Current request: Address the specific user question or need

Response Structure:
1. Direct answer to user's question
2. Relevant details and explanations
3. Personalized recommendations based on user profile
4. Suggested next actions or follow-up questions

Generate responses in Korean with professional wedding planning expertise."""

ERROR_HANDLER_SYSTEM_PROMPT = """You are an error recovery specialist for a wedding planning AI system.
Your role is to provide helpful, user-friendly error messages and suggest recovery actions.

Error Categories:
1. Input validation errors: Guide users on proper input format
2. System connectivity issues: Explain temporary service interruptions  
3. Data conflicts: Help resolve conflicting information
4. Tool execution failures: Suggest alternative approaches

Response Principles:
1. Never expose technical error details to users
2. Always provide constructive next steps
3. Maintain a helpful, apologetic tone
4. Offer alternative ways to achieve the user's goal
5. Include contact information for persistent issues

Generate error responses in Korean with empathetic, solution-focused messaging."""

# ============= CORE PROCESSING NODES =============

def parsing_node(state: State) -> State:
    """
    Parsing Node - Input Analysis and Intent Recognition
    
    Purpose: Analyze user input to extract structured information for routing decisions.
    This node serves as the entry point for all user requests, transforming natural
    language input into structured data that other nodes can process.
    
    Key Functions:
    - Natural language intent classification
    - Entity extraction (venues, locations, dates, budgets)
    - User emotion and urgency detection  
    - Confidence scoring for parsing accuracy
    
    Input State:
    - user_input: Raw user message text
    - user_id: User identifier for context
    
    Output State:
    - vendor_type: Extracted service category 
    - region_keyword: Location preferences
    - intent_hint: Classified user intention
    - update_type: Profile update requirements
    - total_budget_manwon: Budget information
    - parsing_confidence: Extraction confidence score
    """
    
    touch_processing_timestamp(state)
    user_input = state.get('user_input', '')
    
    if not user_input or not user_input.strip():
        state['status'] = "error"
        state['reason'] = "Empty user input provided"
        return state

    try:
        # LLM-based parsing with structured output
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": PARSING_SYSTEM_PROMPT},
                {"role": "user", "content": f"ì‚¬ìš©ì ì…ë ¥: {user_input}"}
            ],
            temperature=0.1,
            max_tokens=500
        )
        
        # Parse LLM response
        parsed_response = json.loads(response.choices[0].message.content)
        
        # Update state with extracted information
        state['vendor_type'] = parsed_response.get('vendor_type')
        state['region_keyword'] = parsed_response.get('region') 
        state['intent_hint'] = parsed_response.get('intent_hint', 'general')
        state['update_type'] = parsed_response.get('update_type')
        state['parsing_confidence'] = parsed_response.get('confidence', 0.0)
        state['raw_llm_response'] = parsed_response
        
        # Handle budget extraction with proper conversion
        budget = parsed_response.get('budget_manwon')
        if budget and isinstance(budget, (int, float)):
            state['total_budget_manwon'] = int(budget)
        
        state['status'] = "ok"
        
    except Exception as e:
        state['status'] = "error"
        state['reason'] = f"Parsing node error: {str(e)}"
        state['intent_hint'] = "general"  # Fallback to general response
    
    return state


def memo_check_node(state: State) -> State:
    """
    Memory Check Node - User Context Loading and Validation
    
    Purpose: Load and validate user's long-term memory from persistent storage.
    This node ensures conversation continuity by retrieving historical context,
    preferences, and previous decisions.
    
    Key Functions:
    - JSON-based memory file loading and validation
    - New user initialization (create empty memo)
    - Memory integrity checking (user ID matching, schema validation)
    - Previous conversation context restoration
    
    Input State:
    - user_id: Unique user identifier
    
    Output State:
    - user_memo: Complete user memory structure
    - memo_file_path: File system path to memory storage
    - memo_needs_update: Flag indicating if memory requires updates
    - Profile fields copied for quick access (budget, wedding_date, guest_count)
    """
    
    user_id = state.get('user_id')
    if not user_id:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ user_id ê°€ì ¸ì˜¤ê¸°
        user_id = os.getenv("DEFAULT_USER_ID", "mvp-test-user")
        
        # stateì— user_id ì„¤ì •
        state['user_id'] = user_id
        
        print(f"ğŸ”§ MVP ëª¨ë“œ: ê¸°ë³¸ user_id '{user_id}' ì‚¬ìš©")
    
    if not user_id:
        state['status'] = "error"
        state['reason'] = "No user_id provided for memory check and no default user_id configured"
        return state
    
    try:
        memo_file_path = get_memo_file_path(user_id)
        state['memo_file_path'] = memo_file_path
        
        if os.path.exists(memo_file_path):
            # Load existing memory
            with open(memo_file_path, 'r', encoding='utf-8') as f:
                user_memo = json.load(f)
            
            # Validate memory structure
            if not isinstance(user_memo, dict) or 'profile' not in user_memo:
                raise ValueError("Invalid memory format: missing required structure")
            
            # Version compatibility check
            if 'version' not in user_memo:
                user_memo['version'] = "1.0"
            
            # User ID verification
            memo_user_id = user_memo.get('profile', {}).get('user_id')
            if memo_user_id != user_id:
                raise ValueError(f"User ID mismatch: expected {user_id}, found {memo_user_id}")
            
            state['user_memo'] = user_memo
            state['memo_needs_update'] = False
            
        else:
            # Create new user memory
            user_memo = create_empty_user_memo(user_id)
            state['user_memo'] = user_memo
            state['memo_needs_update'] = True
        
        # Copy profile data for quick access
        profile = user_memo.get('profile', {})
        if profile.get('total_budget_manwon'):
            state['total_budget_manwon'] = profile['total_budget_manwon']
        if profile.get('wedding_date'):
            state['wedding_date'] = profile['wedding_date']
        if profile.get('guest_count'):
            state['guest_count'] = profile['guest_count']
        if profile.get('preferred_locations'):
            state['preferred_locations'] = profile['preferred_locations']
        
        state['status'] = "ok"
        
    except Exception as e:
        state['status'] = "error"
        state['reason'] = f"Memory check error: {str(e)}"
        # Create fallback empty memory
        state['user_memo'] = create_empty_user_memo(user_id)
        state['memo_needs_update'] = True
        
    return state


def conditional_router(state: State) -> State:
    """
    Conditional Router - Intelligent Decision Hub
    
    Purpose: Analyze user intent and current context to determine the optimal
    processing path. This node serves as the central decision point that routes
    requests to appropriate specialized nodes.
    
    Key Functions:
    - Intent-based routing logic (recommend/tool/general)
    - Context-aware decision making using user memory
    - Tool requirement analysis and planning
    - Information gap detection and handling
    
    Routing Logic:
    - "recommendation": Venue/vendor suggestions with sufficient user profile
    - "tool_execution": Database updates, calculations, searches
    - "general_response": Advice, FAQ, general consultation
    - "error_handler": Invalid requests or system errors
    
    Input State:
    - intent_hint: Parsed user intention
    - vendor_type: Service category if specified
    - region_keyword: Location preference
    - user_memo: Historical user context
    
    Output State:
    - routing_decision: Selected processing path
    - tools_to_execute: List of required tools
    - reason: Explanation for routing decision
    """
    
    touch_processing_timestamp(state)
    intent_hint = state.get('intent_hint', 'general')
    vendor_type = state.get('vendor_type')
    region_keyword = state.get('region_keyword')
    user_memo = state.get('user_memo', {})
    user_input = state.get('user_input', '')

    try:
        # Route based on parsed intent
        if intent_hint == "recommend":
            state['routing_decision'] = "recommendation"
            state['tools_to_execute'] = []
            state['reason'] = "User seeking wedding vendor recommendations"
            
        elif intent_hint == "tool":
            state['routing_decision'] = "tool_execution"
            
            # Determine required tools based on request content
            tools_needed = []
            
            # Check for calculation needs
            if any(keyword in user_input for keyword in ['ê³„ì‚°', 'ì˜ˆì‚°', 'ì´ì•¡', 'ë¹„ìš©', 'ê°€ê²©']):
                tools_needed.append("calculator_tool")
                tools_needed.append("db_query_tool")
            
            # Check for database query needs  
            if vendor_type or region_keyword:
                if "db_query_tool" not in tools_needed:
                    tools_needed.append("db_query_tool")
            
            # Check for web search needs
            if any(keyword in user_input for keyword in ['ìµœì‹ ', 'ìš”ì¦˜', 'íŠ¸ë Œë“œ', 'í›„ê¸°', 'ë¦¬ë·°']):
                tools_needed.append("web_search_tool")
            
            # Check for user data updates
            update_type = state.get('update_type')
            if update_type:
                tools_needed.append("user_db_update_tool")
            
            # Default to database query if no specific tools identified
            if not tools_needed:
                tools_needed.append("db_query_tool")
            
            state['tools_to_execute'] = tools_needed
            state['reason'] = f"Tool execution needed: {', '.join(tools_needed)}"
            
        else:  # intent_hint == "general"
            state['routing_decision'] = "general_response"
            state['tools_to_execute'] = []
            state['reason'] = "General conversation or FAQ request"
        
        # Information gap analysis for recommendations
        profile = user_memo.get('profile', {})
        missing_info = []
        if not profile.get('wedding_date'):
            missing_info.append("wedding_date")
        if not profile.get('total_budget_manwon'):
            missing_info.append("budget")
        if not profile.get('guest_count'):
            missing_info.append("guest_count")
        
        # Redirect insufficient profile recommendations to general response
        if (len(missing_info) >= 3 and 
            state.get('routing_decision') == "recommendation" and 
            not vendor_type):
            state['routing_decision'] = "general_response"
            state['tools_to_execute'] = []
            state['reason'] = "Insufficient profile info for recommendation, providing general advice"

        state['status'] = "ok"
    
    except Exception as e:
        state['status'] = "error"
        state['reason'] = f"Router error: {str(e)}"
        state['routing_decision'] = "error_handler"
    
    return state

# ============= SPECIALIZED ACTION NODES =============

def recommendation_node(state: State) -> State:
    """
    Recommendation Node - Personalized Wedding Vendor Suggestions
    
    Purpose: Generate tailored wedding vendor recommendations based on user
    preferences, budget constraints, and regional preferences. This node
    implements intelligent matching algorithms for optimal vendor selection.
    
    Key Functions:
    - Requirement analysis and parameter optimization
    - Memory-based personalized recommendation generation  
    - Recommendation parameter customization
    - Algorithm selection (trending/location/budget-based)
    
    Recommendation Scenarios:
    - Venue-based: "ì°¾ê³  ìˆëŠ” ì˜ˆì‹ì¥ ì¶”ì²œí•´ì£¼ì„¸ìš”"
    - Location-based: "ê°•ë‚¨ ìŠ¤íŠœë””ì˜¤ ì¶”ì²œ"
    - Budget-based: "ì˜ˆì‚° ë§ëŠ” ì›¨ë”©í™€ ì°¾ì•„ì£¼ì„¸ìš”"
    
    Input State:
    - vendor_type: Service category for recommendations
    - user_memo: User preferences and constraints
    - region_keyword: Location preferences
    - total_budget_manwon: Budget constraints
    
    Output State:
    - tools_to_execute: Updated with recommendation-specific tools
    - recommendation_params: Parameters for recommendation algorithm
    """
    
    touch_processing_timestamp(state)
    vendor_type = state.get('vendor_type')
    user_memo = state.get('user_memo', {})
    region_keyword = state.get('region_keyword')
    budget = state.get('total_budget_manwon')
    
    try:
        # For MVP, pass through to tool execution with enhanced parameters
        profile = user_memo.get('profile', {})
        
        # Build recommendation context
        recommendation_context = {
            'vendor_type': vendor_type,
            'region': region_keyword or profile.get('preferred_locations', []),
            'budget_manwon': budget or profile.get('total_budget_manwon'),
            'guest_count': profile.get('guest_count'),
            'wedding_date': profile.get('wedding_date'),
            'recommendation_type': 'personalized'
        }
        
        # Store recommendation parameters for tool execution
        state['recommendation_params'] = recommendation_context
        
        # Set tools for recommendation processing
        tools_needed = ["db_query_tool"]
        if any(keyword in state.get('user_input', '') for keyword in ['íŠ¸ë Œë“œ', 'ì¸ê¸°', 'í›„ê¸°']):
            tools_needed.append("web_search_tool")
        
        state['tools_to_execute'] = tools_needed
        state['reason'] = f"Generating recommendations for {vendor_type or 'general wedding services'}"
        state['status'] = "ok"
        
    except Exception as e:
        state['status'] = "error"
        state['reason'] = f"Recommendation node error: {str(e)}"
        
    return state


def tool_execution_node(state: State) -> State:
    """
    Tool Execution Node - External Service Integration Hub
    
    Purpose: Execute external tools and services based on routing decisions.
    This node handles complex parameter generation, tool orchestration,
    and result aggregation for various wedding planning tasks.
    
    Key Functions:
    - LLM-based dynamic parameter generation for each tool
    - Parallel tool execution with error isolation
    - Result standardization and quality validation
    - Execution logging and performance monitoring
    
    Supported Tools:
    - db_query_tool: Wedding vendor database searches
    - web_search_tool: Current trends and review searches  
    - calculator_tool: Budget and timeline calculations
    - user_db_update_tool: Profile and preference updates
    
    Input State:
    - tools_to_execute: List of tools to run
    - user_input: Original user request for context
    - State context: All relevant user and session data
    
    Output State:
    - tool_results: Standardized results from all executed tools
    - tool_execution_log: Detailed execution metrics and logs
    """
    touch_processing_timestamp(state)
    tools_to_execute = state.get('tools_to_execute', [])
    
    # tool_resultsë¥¼ ì´ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬í•˜ì—¬ ì´ì „ ë¬¸ì œë¥¼ ì›ì²œì ìœ¼ë¡œ ë°©ì§€í•©ë‹ˆë‹¤.
    tool_results = []
    execution_log = []
    
    try:
        if not tools_to_execute:
            state['tool_results'] = []
            state['reason'] = "No tools to execute"
            state['status'] = "ok"
            return state
        
        print(f"ğŸ”§ ì‹¤í–‰í•  íˆ´: {tools_to_execute}")
        
        for tool_name in tools_to_execute:
            execution_start = datetime.now()
            result = {}
            
            try:
                print(f"âš¡ {tool_name} ì‹¤í–‰ ì¤‘...")
                
                if tool_name == "db_query_tool":
                    result = execute_db_query_tool(state)
                elif tool_name == "web_search_tool":
                    result = execute_web_search_tool(state)
                elif tool_name == "calculator_tool":
                    result = execute_calculator_tool(state)
                elif tool_name == "user_db_update_tool":
                    result = execute_user_db_update_tool(state)
                else:
                    result = {
                        "success": False,
                        "error": f"Unknown tool: {tool_name}",
                        "data": None
                    }
                
                execution_end = datetime.now()
                execution_time = (execution_end - execution_start).total_seconds()
                
                # ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (tool_name í¬í•¨)
                tool_results.append({
                    "tool_name": tool_name,
                    "output": result
                })
                
                log_entry = {
                    "tool_name": tool_name,
                    "execution_time": execution_time,
                    "success": result.get("success", False),
                    "timestamp": execution_end.isoformat()
                }
                execution_log.append(log_entry)
                
                print(f"âœ… {tool_name} ì™„ë£Œ ({execution_time:.2f}ì´ˆ)")
                
                if not result.get("success", False):
                    print(f"âš ï¸ {tool_name} ì‹¤í–‰ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                
            except Exception as e:
                error_result = {
                    "success": False,
                    "error": f"Tool execution failed: {str(e)}",
                    "data": None
                }
                tool_results.append({
                    "tool_name": tool_name,
                    "output": error_result
                })
                print(f"âŒ {tool_name} ì—ëŸ¬: {str(e)}")

        successful_tools_count = sum(1 for r in tool_results if r['output'].get("success"))
        
        state['tool_results'] = tool_results # ìµœì¢…ì ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ stateì— ì €ì¥
        state['execution_log'] = execution_log
        state['status'] = "ok"
        state['reason'] = f"Executed {successful_tools_count}/{len(tools_to_execute)} tools successfully"
        
        print(f"ğŸ“Š ì‹¤í–‰ ì™„ë£Œ: ì„±ê³µ {successful_tools_count}, ì‹¤íŒ¨ {len(tools_to_execute) - successful_tools_count}")
        
    except Exception as e:
        state['tool_results'] = []
        state['status'] = "error"
        state['reason'] = f"Tool execution node failed: {str(e)}"
        print(f"ğŸ’¥ tool_execution_node ì „ì²´ ì‹¤íŒ¨: {str(e)}")
    
    return state


def execute_db_query_tool(state: dict) -> dict:
    """
    ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ íˆ´ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    from tools import db_query_tool
    
    try:
        vendor_type = state.get('vendor_type')
        region_keyword = state.get('region_keyword')
        budget = (state.get('user_memo', {}).get('profile', {})).get('total_budget_manwon')
        
        table_map = {
            "wedding_hall": "wedding_hall",
            "studio": "studio",
            "wedding_dress": "wedding_dress",
            "makeup": "makeup"
        }
        table_name = table_map.get(vendor_type, "wedding_hall") # ê¸°ë³¸ê°’ ì„¤ì •
        
        query = f"SELECT name, location, price_manwon FROM {table_name}"
        conditions = []
        
        if region_keyword:
            conditions.append(f"location LIKE '%{region_keyword}%'")
        if budget:
            conditions.append(f"price_manwon <= {budget}")
        
        if conditions:
            query += " WHERE " + " AND ".join(conditions)
        
        query += " ORDER BY price_manwon DESC LIMIT 5"
        
        print(f"ğŸ—„ï¸ DB ì¿¼ë¦¬: {query}")
        
        # db_query_toolì€ ì´ì œ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        return db_query_tool(query)
        
    except Exception as e:
        return {"success": False, "error": f"DB query execution failed: {str(e)}", "data": None}


def execute_web_search_tool(state: dict) -> dict:
    """
    ì›¹ ê²€ìƒ‰ íˆ´ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    from tools import web_search_tool
    
    try:
        vendor_type = state.get('vendor_type', '')
        region_keyword = state.get('region_keyword', '')
        user_input = state.get('user_input', '')
        
        search_terms = []
        if vendor_type:
            search_terms.append(f"{region_keyword} {vendor_type} ì¶”ì²œ")
        if any(keyword in user_input for keyword in ['íŠ¸ë Œë“œ', 'ìµœì‹ ', 'ìš”ì¦˜', 'ì¸ê¸°']):
            search_terms.append("ìµœì‹  ì›¨ë”© íŠ¸ë Œë“œ")
        if any(keyword in user_input for keyword in ['í›„ê¸°', 'ë¦¬ë·°']):
            search_terms.append("í›„ê¸°")

        search_query = " ".join(search_terms) or "ê²°í˜¼ ì¤€ë¹„ ì •ë³´"
        
        print(f"ğŸŒ ì›¹ ê²€ìƒ‰: {search_query}")
        
        # web_search_toolì€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        return web_search_tool(search_query)
        
    except Exception as e:
        return {"success": False, "error": f"Web search execution failed: {str(e)}", "data": None}


def execute_calculator_tool(state: dict) -> dict:
    """
    ê³„ì‚°ê¸° íˆ´ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    from tools import calculator_tool
    
    try:
        user_input = state.get('user_input', '')
        
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ê°„ë‹¨í•œ ìˆ˜í•™ í‘œí˜„ì‹ ì°¾ê¸° (ì˜ˆ: "ì´ ì˜ˆì‚° 5000ë§Œì›ì—ì„œ 300 ë¹¼ë©´ ì–¼ë§ˆ?")
        match = re.search(r'([\d\s\+\-\*\/\(\)]+)', user_input)
        if match:
            expression = match.group(1).strip()
            # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°ëŠ” ì œì™¸
            if any(op in expression for op in "+-*/"):
                print(f"ğŸ§® ê³„ì‚°ê¸° ì‹¤í–‰: {expression}")
                return calculator_tool(expression)

        return {"success": False, "error": "No valid calculation expression found in user input", "data": None}

    except Exception as e:
        return {"success": False, "error": f"Calculator execution failed: {str(e)}", "data": None}


def execute_user_db_update_tool(state: dict) -> dict:
    """
    ì‚¬ìš©ì ì •ë³´ ì—…ë°ì´íŠ¸ íˆ´ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    from tools import user_db_update_tool
    
    try:
        user_id = state.get('user_id')
        update_type = state.get('update_type')
        
        if not user_id or not update_type:
            return {"success": False, "error": "User ID or update type is missing", "data": None}

        # ìƒíƒœì—ì„œ ì§ì ‘ ê°’ì„ ê°€ì ¸ì™€ íˆ´ì— ì „ë‹¬
        if update_type == "budget":
            new_value = state.get('total_budget_manwon')
            field_to_update = "total_budget_manwon"
        # ë‹¤ë¥¸ ì—…ë°ì´íŠ¸ íƒ€ì…(wedding_date, guest_count)ì— ëŒ€í•œ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
        else:
             return {"success": False, "error": f"Unsupported update type: {update_type}", "data": None}

        if new_value is not None:
             print(f"ğŸ‘¤ í”„ë¡œí•„ ì—…ë°ì´íŠ¸: {field_to_update} -> {new_value}")
             return user_db_update_tool(state, user_id, field_to_update, new_value)
        
        return {"success": False, "error": "No value found in state for the requested update", "data": None}
    
    except Exception as e:
        return {"success": False, "error": f"User update execution failed: {str(e)}", "data": None}
    
def general_response_node(state: dict) -> dict:
    """
    General response node that handles non-specific queries with contextual wedding topic guidance.
    
    This node provides comprehensive responses to general questions while maintaining user engagement
    through natural conversation flow. The node serves as the fallback handler for queries that
    don't require specific tool execution or vendor recommendations.
    
    Core Functionality:
    - Processes general questions with thorough, helpful responses
    - Maintains natural conversation flow without forced topic redirection
    - Subtly guides conversation toward wedding planning topics when appropriate
    - Leverages user memory context to personalize responses
    - Provides FAQ-style answers for common wedding planning questions
    - Handles casual conversation and relationship-building interactions
    
    Response Strategy:
    - Primary Focus: Answer the user's actual question comprehensively
    - Secondary Goal: Natural topic bridging to wedding planning when contextually appropriate
    - Personalization: Incorporate user profile information when relevant
    - Tone Management: Maintain helpful, friendly, and professional tone
    - Engagement: End with gentle conversation steering toward wedding topics
    
    The node avoids forced topic changes but creates natural opportunities for wedding-related
    follow-up questions through contextual bridges and relevant suggestions.
    
    Args:
        state (dict): State containing user_input, user_memo, and conversation context
        
    Returns:
        dict: Updated state with response_content and conversation guidance
    """
    
    user_input = state.get('user_input', '').strip()
    user_memo = state.get('user_memo', {})
    user_id = state.get('user_id')
    
    try:
        if not user_input:
            state['status'] = "error"
            state['reason'] = "No user input provided for general response"
            return state
        
        # Analyze input to determine response approach
        response_context = _analyze_input_context(user_input, user_memo)
        
        # Generate core response based on question type
        core_response = _generate_core_response(user_input, response_context, user_memo)
        
        # Add natural wedding topic bridge if appropriate
        final_response = _add_wedding_topic_bridge(core_response, response_context, user_memo)
        
        # Update state with response
        state['response_content'] = final_response
        state['response_metadata'] = {
            'response_type': 'general_response',
            'topic_bridge_added': response_context.get('bridge_appropriate', False),
            'personalization_level': response_context.get('personalization_level', 'basic'),
            'generated_at': datetime.now().isoformat()
        }
        
        state['status'] = "ok"
        
        print(f"ğŸ’¬ ì¼ë°˜ ì‘ë‹µ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(final_response)}ì)")
        
        return state
        
    except Exception as e:
        state['status'] = "error"
        state['reason'] = f"General response generation failed: {str(e)}"
        print(f"âŒ ì¼ë°˜ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return state


def _analyze_input_context(user_input: str, user_memo: dict) -> dict:
    """Analyze user input to determine appropriate response strategy."""
    
    input_lower = user_input.lower()
    profile = user_memo.get('profile', {})
    
    context = {
        'question_type': 'general',
        'topic_category': 'other',
        'personalization_level': 'basic',
        'bridge_appropriate': True,
        'wedding_related': False
    }
    
    # Detect question types
    if any(word in input_lower for word in ['ì•ˆë…•', 'í•˜ì´', 'ì¢‹ì€', 'ë‚ ì”¨', 'ê¸°ë¶„']):
        context['question_type'] = 'greeting'
        context['topic_category'] = 'casual'
    
    elif any(word in input_lower for word in ['ë­', 'ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ', 'ì–´ë””ì„œ']):
        context['question_type'] = 'inquiry'
        context['topic_category'] = 'informational'
    
    elif any(word in input_lower for word in ['ê²°í˜¼', 'ì›¨ë”©', 'ì‹ í˜¼', 'ê²°í˜¼ì‹', 'ì˜ˆì‹', 'ì‹ ë¶€', 'ì‹ ë‘']):
        context['wedding_related'] = True
        context['question_type'] = 'wedding_general'
        context['topic_category'] = 'wedding'
        context['bridge_appropriate'] = False  # Already wedding-related
    
    elif any(word in input_lower for word in ['ê°ì‚¬', 'ê³ ë§ˆì›Œ', 'ë„ì›€', 'ì¢‹ì•„']):
        context['question_type'] = 'appreciation'
        context['topic_category'] = 'positive'
    
    elif any(word in input_lower for word in ['í˜ë“¤', 'ì–´ë ¤ì›Œ', 'ê³ ë¯¼', 'ê±±ì •']):
        context['question_type'] = 'concern'
        context['topic_category'] = 'supportive'
    
    # Determine personalization level based on available user info
    if profile.get('name') or profile.get('wedding_date'):
        context['personalization_level'] = 'high'
    elif profile.get('user_id'):
        context['personalization_level'] = 'medium'
    
    # Adjust bridge appropriateness based on context
    if context['question_type'] in ['appreciation', 'concern']:
        context['bridge_appropriate'] = True
    elif context['topic_category'] == 'casual':
        context['bridge_appropriate'] = True
    
    return context


def _generate_core_response(user_input: str, context: dict, user_memo: dict) -> str:
    """Generate core response based on question type and context."""
    
    question_type = context.get('question_type', 'general')
    profile = user_memo.get('profile', {})
    user_name = profile.get('name', '')
    
    # Response templates based on question type
    if question_type == 'greeting':
        responses = [
            f"ì•ˆë…•í•˜ì„¸ìš”{f' {user_name}ë‹˜' if user_name else ''}! ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë–»ê²Œ ë³´ë‚´ê³  ê³„ì‹ ê°€ìš”?",
            f"ë°˜ê°€ì›Œìš”{f' {user_name}ë‹˜' if user_name else ''}! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
            "ì¢‹ì€ í•˜ë£¨ë„¤ìš”! ì˜¤ëŠ˜ì€ ì–´ë–¤ ì¼ì´ ìˆìœ¼ì…¨ë‚˜ìš”?"
        ]
        return _select_appropriate_response(responses, context)
    
    elif question_type == 'wedding_general':
        return _handle_wedding_general_question(user_input, user_memo)
    
    elif question_type == 'inquiry':
        return _handle_general_inquiry(user_input, context, user_memo)
    
    elif question_type == 'appreciation':
        responses = [
            "ë„ì›€ì´ ë˜ì—ˆë‹¤ë‹ˆ ì •ë§ ê¸°ë»ìš”! ì–¸ì œë“  ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.",
            "ê°ì‚¬í•˜ë‹¤ê³  ë§ì”€í•´ ì£¼ì…”ì„œ ê°ë™ì´ì—ìš”. ë” ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½í•´ ì£¼ì„¸ìš”!",
            "ì²œë§Œì—ìš”! ì—¬ëŸ¬ë¶„ì˜ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë°˜ì‘ì´ ì €ì—ê²ŒëŠ” ìµœê³ ì˜ ë³´ìƒì…ë‹ˆë‹¤."
        ]
        return _select_appropriate_response(responses, context)
    
    elif question_type == 'concern':
        responses = [
            "ê±±ì •ì´ ë§ìœ¼ì‹œêµ°ìš”. ì²œì²œíˆ í•˜ë‚˜ì”© í•´ê²°í•´ ë‚˜ê°€ë©´ ë¶„ëª…íˆ ì¢‹ì€ ê²°ê³¼ê°€ ìˆì„ ê±°ì˜ˆìš”.",
            "ì–´ë ¤ìš´ ìƒí™©ì´ì‹œë„¤ìš”. í•˜ì§€ë§Œ ëª¨ë“  ë¬¸ì œì—ëŠ” í•´ê²°ì±…ì´ ìˆë‹¤ê³  ìƒê°í•´ìš”. í•¨ê»˜ ì°¾ì•„ë³¼ê¹Œìš”?",
            "í˜ë“  ì‹œê°„ì„ ë³´ë‚´ê³  ê³„ì‹  ê²ƒ ê°™ì•„ìš”. ì œê°€ ë„ìš¸ ìˆ˜ ìˆëŠ” ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”."
        ]
        return _select_appropriate_response(responses, context)
    
    else:
        # General fallback response
        return _generate_general_fallback_response(user_input, user_memo)


def _handle_wedding_general_question(user_input: str, user_memo: dict) -> str:
    """Handle general wedding-related questions."""
    
    profile = user_memo.get('profile', {})
    input_lower = user_input.lower()
    
    if 'ì¤€ë¹„' in input_lower and ('í˜ë“¤' in input_lower or 'ì–´ë ¤ì›Œ' in input_lower):
        return """ê²°í˜¼ ì¤€ë¹„ê°€ í˜ë“œì‹œì£ ? ì •ë§ ë§ì€ ë¶„ë“¤ì´ ê°™ì€ ê³ ë¯¼ì„ í•˜ì„¸ìš”. 
ê²°í˜¼ì‹ ì¤€ë¹„ëŠ” ë‹¨ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ìš”. 
ë¨¼ì € ì˜ˆì‚°ê³¼ ë‚ ì§œ, í•˜ê° ê·œëª¨ë¥¼ ì •í•˜ê³ , ê·¸ ë‹¤ìŒì— ì˜ˆì‹ì¥ê³¼ ìŠ¤íŠœë””ì˜¤ë¥¼ ì„ íƒí•˜ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë ¤ìš”."""
    
    elif 'ì–¸ì œ' in input_lower and 'ì‹œì‘' in input_lower:
        wedding_date = profile.get('wedding_date')
        if wedding_date:
            return f"""ê²°í˜¼ì‹ì´ {wedding_date}ë¡œ ì˜ˆì •ë˜ì–´ ìˆìœ¼ì‹œë‹ˆ, ì§€ê¸ˆë¶€í„° ì°¨ê·¼ì°¨ê·¼ ì¤€ë¹„í•˜ì‹œë©´ ì¶©ë¶„í•´ìš”.
ë³´í†µ ê²°í˜¼ì‹ 3-6ê°œì›” ì „ë¶€í„° ë³¸ê²©ì ìœ¼ë¡œ ì¤€ë¹„í•˜ì‹œëŠ” ë¶„ë“¤ì´ ë§ì•„ìš”.
ì˜ˆì‹ì¥ ì˜ˆì•½ì€ ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ê³ , ë“œë ˆìŠ¤ë‚˜ í„±ì‹œë„ëŠ” 2-3ê°œì›” ì „ì— ì¤€ë¹„í•˜ì‹œë©´ ë©ë‹ˆë‹¤."""
        else:
            return """ê²°í˜¼ ì¤€ë¹„ëŠ” ë³´í†µ ê²°í˜¼ì‹ 3-6ê°œì›” ì „ë¶€í„° ì‹œì‘í•˜ì‹œëŠ” ê²ƒì„ ì¶”ì²œí•´ìš”.
ë¨¼ì € ì˜ˆì‹ ë‚ ì§œë¶€í„° ì •í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ê² ë„¤ìš”."""
    
    else:
        return """ê²°í˜¼ ì¤€ë¹„ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œêµ°ìš”! 
ê²°í˜¼ì‹ ì¤€ë¹„ëŠ” ìƒê°ë³´ë‹¤ ë§ì€ ê²ƒë“¤ì„ ê³ ë ¤í•´ì•¼ í•˜ì§€ë§Œ, ì²´ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•˜ë©´ ì¶©ë¶„íˆ í•´ë‚¼ ìˆ˜ ìˆì–´ìš”.
ì˜ˆì‚°, ë‚ ì§œ, ì˜ˆì‹ì¥, ìŠ¤íŠœë””ì˜¤ ë“± ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"""


def _handle_general_inquiry(user_input: str, context: dict, user_memo: dict) -> str:
    """Handle general inquiry questions."""
    
    input_lower = user_input.lower()
    
    # Common general questions with helpful responses
    if any(word in input_lower for word in ['ë‚ ì”¨', 'ê¸°ì˜¨', 'ì˜¨ë„']):
        return """ì˜¤ëŠ˜ ë‚ ì”¨ ì •ë³´ëŠ” ë‚ ì”¨ ì•±ì´ë‚˜ í¬í„¸ ì‚¬ì´íŠ¸ì—ì„œ ì •í™•íˆ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”.
ë‚ ì”¨ê°€ ì¢‹ì€ ë‚ ì´ë©´ ì•¼ì™¸ ì›¨ë”©ì´ë‚˜ ìŠ¤íŠœë””ì˜¤ ì´¬ì˜í•˜ê¸°ì—ë„ ì¢‹ê² ë„¤ìš”!"""
    
    elif any(word in input_lower for word in ['ì‹œê°„', 'ëª‡ì‹œ', 'ì–¸ì œ']):
        return """ì •í™•í•œ ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•˜ì‹œêµ°ìš”. 
ê²°í˜¼ì‹ ì‹œê°„ ê³„íšì„ ì„¸ìš°ì‹¤ ë•ŒëŠ” ë³´í†µ ë‚® 12ì‹œë‚˜ 2ì‹œ, 4ì‹œì— ì˜ˆì‹ì„ ë§ì´ í•˜ì„¸ìš”."""
    
    elif any(word in input_lower for word in ['ìŒì‹', 'ìš”ë¦¬', 'ë§›ì§‘']):
        return """ë§›ìˆëŠ” ìŒì‹ì— ê´€ì‹¬ì´ ë§ìœ¼ì‹œë„¤ìš”! 
ê²°í˜¼ì‹ í”¼ë¡œì—°ì´ë‚˜ ì‹ í˜¼ì—¬í–‰ ë§›ì§‘ íˆ¬ì–´ë„ ë¯¸ë¦¬ ê³„íší•´ ë³´ì‹œë©´ ì–´ë–¨ê¹Œìš”?"""
    
    elif any(word in input_lower for word in ['ëˆ', 'ë¹„ìš©', 'ê°€ê²©']):
        return """ë¹„ìš©ì— ëŒ€í•´ ê´€ì‹¬ì´ ìˆìœ¼ì‹œêµ°ìš”. 
ê²°í˜¼ ì¤€ë¹„ë„ ì˜ˆì‚° ê³„íšì„ ë¯¸ë¦¬ ì„¸ì›Œë‘ì‹œë©´ í›¨ì”¬ ìˆ˜ì›”í•˜ê²Œ ì§„í–‰í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”."""
    
    else:
        return f"""'{user_input}'ì— ëŒ€í•´ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ ë“œë¦¬ê¸°ëŠ” ì–´ë µì§€ë§Œ, 
ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì•„ì„œ ë„ì›€ì„ ë“œë¦¬ê³  ì‹¶ì–´ìš”."""


def _generate_general_fallback_response(user_input: str, user_memo: dict) -> str:
    """Generate fallback response for general questions."""
    
    profile = user_memo.get('profile', {})
    user_name = profile.get('name', '')
    
    responses = [
        f"í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì´ë„¤ìš”{f' {user_name}ë‹˜' if user_name else ''}! ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œë©´ ë” ë„ì›€ì´ ë  ê²ƒ ê°™ì•„ìš”.",
        f"ì¢‹ì€ ì ì„ ë§ì”€í•´ ì£¼ì…¨ë„¤ìš”. ì¡°ê¸ˆ ë” ìì„¸íˆ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.",
        f"ê·¸ëŸ° ê´€ì ì—ì„œ ìƒê°í•´ ë³´ì‹œëŠ”êµ°ìš”! ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ê¶ê¸ˆí•˜ì‹ ì§€ ì•Œë ¤ì£¼ì‹œë©´ ì¢‹ê² ì–´ìš”."
    ]
    
    return responses[hash(user_input) % len(responses)]


def _add_wedding_topic_bridge(core_response: str, context: dict, user_memo: dict) -> str:
    """Add natural wedding topic bridge to the response if appropriate."""
    
    if not context.get('bridge_appropriate', False):
        return core_response
    
    if context.get('wedding_related', False):
        return core_response  # Already wedding-related, no bridge needed
    
    profile = user_memo.get('profile', {})
    wedding_date = profile.get('wedding_date')
    
    # Generate contextual bridges based on user profile
    if wedding_date:
        bridge_options = [
            f" ê·¸ëŸ°ë° {wedding_date} ê²°í˜¼ì‹ ì¤€ë¹„ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ê³  ìˆë‚˜ìš”?",
            f" ì°¸, ê²°í˜¼ì‹ ì¤€ë¹„ ì¤‘ì´ì‹ ë° ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
            f" ê²°í˜¼ ì¤€ë¹„ë¡œ ë°”ì˜ì‹¤ í…ë°, ë‹¤ë¥¸ ê¶ê¸ˆí•œ ì ì€ ì—†ìœ¼ì‹ ì§€ìš”?"
        ]
    elif profile.get('total_budget_manwon'):
        budget = profile.get('total_budget_manwon')
        bridge_options = [
            f" ê²°í˜¼ ì¤€ë¹„ ì˜ˆì‚° {budget}ë§Œì›ìœ¼ë¡œ ê³„íší•˜ê³  ê³„ì‹œëŠ”ë°, ì–´ë–¤ ë¶€ë¶„ë¶€í„° ì‹œì‘í•´ë³¼ê¹Œìš”?",
            " ê²°í˜¼ ì¤€ë¹„ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ê³  ìˆë‚˜ìš”?",
            " í˜¹ì‹œ ê²°í˜¼ ì¤€ë¹„ ê´€ë ¨í•´ì„œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!"
        ]
    else:
        bridge_options = [
            " í˜¹ì‹œ ê²°í˜¼ ì¤€ë¹„ ê³„íšì´ ìˆìœ¼ì‹œë‹¤ë©´ ì–¸ì œë“  ë„ì›€ì„ ìš”ì²­í•´ ì£¼ì„¸ìš”!",
            " ê²°í˜¼ì´ë‚˜ ì›¨ë”©ê³¼ ê´€ë ¨ëœ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
            " ê²°í˜¼ ì¤€ë¹„ì— ëŒ€í•œ ì¡°ì–¸ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½í•´ ì£¼ì„¸ìš”!"
        ]
    
    # Select appropriate bridge based on context
    question_type = context.get('question_type', 'general')
    if question_type == 'concern':
        # More supportive bridge for concerns
        bridge = " ê²°í˜¼ ì¤€ë¹„ë¡œ ê³ ë¯¼ì´ ìˆìœ¼ì‹œë‹¤ë©´ í•¨ê»˜ í•´ê²°ì±…ì„ ì°¾ì•„ë³´ì•„ìš”!"
    elif question_type == 'appreciation':
        # Encouraging bridge for positive interactions
        bridge = " ê²°í˜¼ ì¤€ë¹„ë„ ì´ë ‡ê²Œ ê¸ì •ì ì¸ ë§ˆìŒìœ¼ë¡œ í•˜ì‹œë©´ ë¶„ëª… ë©‹ì§„ ê²°ê³¼ê°€ ìˆì„ ê±°ì˜ˆìš”!"
    else:
        bridge = bridge_options[hash(core_response) % len(bridge_options)]
    
    return core_response + bridge


def _select_appropriate_response(responses: List[str], context: dict) -> str:
    """Select most appropriate response based on context."""
    
    personalization = context.get('personalization_level', 'basic')
    
    if personalization == 'high':
        return responses[0]  # Most personalized
    elif personalization == 'medium':
        return responses[1] if len(responses) > 1 else responses[0]
    else:
        return responses[-1]  # Most generic

def memo_update_node(state: State) -> State:
    """
    Memory Update Node - Persistent Context Management
    
    Purpose: Update user's long-term memory with new information gathered
    during the conversation. This node ensures continuity across sessions
    and enables personalized experiences based on historical interactions.
    
    Key Functions:
    - Tool result processing and memory integration
    - User preference learning and adaptation
    - Conversation history summarization  
    - JSON file persistence with atomic updates
    
    Update Categories:
    - Profile updates: Budget, dates, guest counts, preferences
    - Search history: Query patterns and result preferences
    - Decision history: Choices made and reasoning
    - Interaction patterns: Communication preferences and timing
    
    Input State:
    - tool_results: Results from executed tools to process
    - user_memo: Current memory state to update
    - memo_needs_update: Flag indicating update requirements
    
    Output State:
    - Updated user_memo with new information
    - memo_needs_update: Reset to False after successful updates
    - memo_updates_made: Log of changes made during this session
    """
    
    touch_processing_timestamp(state)
    user_memo = state.get('user_memo')
    tool_results = state.get('tool_results', [])
    memo_file_path = state.get('memo_file_path')
    
    if not user_memo:
        state['status'] = "error"
        state['reason'] = "User memo is missing for update"
        return state
        
    try:
        updates_made = []
        
        # Process each tool result for memory updates
        for result in tool_results:
            if not result.get('success'):
                continue
                
            tool_name = result['tool_name']
            output = result['output']
            
            if tool_name == 'db_query_tool':
                # Record search patterns and preferences
                search_history = user_memo.setdefault('search_history', [])
                if isinstance(output, dict) and output.get('data'):
                    history_entry = {
                        'query_type': 'database_search',
                        'results_count': output['data'].get('total_count', 0),
                        'timestamp': datetime.now().isoformat()
                    }
                    search_history.append(history_entry)
                    updates_made.append({'category': 'search_history', 'action': 'add_search', 'data': history_entry})
                    
            elif tool_name == 'user_db_update_tool':
                # Process profile updates from user_db_update results
                if isinstance(output, dict) and output.get('success'):
                    updated_data = output.get('data', {})
                    profile = user_memo.setdefault('profile', {})
                    
                    # Update profile with new information
                    for key, value in updated_data.get('updated_profile', {}).items():
                        if value is not None:
                            profile[key] = value
                    
                    updates_made.append({
                        'category': 'profile', 
                        'action': 'update_profile', 
                        'data': updated_data
                    })
                    
            elif tool_name == 'web_search_tool':
                # Store external insights and trends
                if isinstance(output, dict) and output.get('success'):
                    preferences = user_memo.setdefault('preferences', {})
                    insights = preferences.setdefault('external_insights', [])
                    
                    search_data = output.get('data', {})
                    if search_data.get('results'):
                        insight_entry = {
                            'source': 'web_search',
                            'query': search_data.get('query', ''),
                            'results_count': search_data.get('total_count', 0),
                            'timestamp': datetime.now().isoformat()
                        }
                        insights.append(insight_entry)
                        updates_made.append({'category': 'preferences', 'action': 'add_insight', 'data': insight_entry})
                        
            elif tool_name == 'calculator_tool':
                # Record calculation history and financial planning
                if isinstance(output, dict) and output.get('success'):
                    calculations = user_memo.setdefault('calculations', [])
                    calc_data = output.get('data', {})
                    
                    calc_entry = {
                        'expression': calc_data.get('expression', ''),
                        'result': calc_data.get('result'),
                        'timestamp': datetime.now().isoformat()
                    }
                    calculations.append(calc_entry)
                    updates_made.append({'category': 'calculations', 'action': 'add_calculation', 'data': calc_entry})
        
        # Update conversation summary if significant changes occurred
        if updates_made:
            user_memo['last_updated'] = datetime.now().isoformat()
            
            # Save updated memory to file
            if memo_file_path:
                with open(memo_file_path, 'w', encoding='utf-8') as f:
                    json.dump(user_memo, f, ensure_ascii=False, indent=2)
                
            state['memo_needs_update'] = False
            state['memo_updates_made'] = updates_made
        
        state['status'] = "ok"
        
    except Exception as e:
        state['status'] = "error"
        state['reason'] = f"Memo update error: {str(e)}"
        
    return state

# ============= RESPONSE GENERATION NODES =============

def response_generation_node(state: State) -> State:
    """
    Response Generation Node - Final User Response Creation
    
    Purpose: Generate the final response to the user by synthesizing information
    from tool results, memory context, and conversation flow. This node creates
    personalized, helpful responses that address user needs comprehensively.
    
    Key Functions:
    - Multi-source content integration (tools + memory + context)
    - Personalized response generation using user preferences
    - Suggestion generation for follow-up actions
    - Response quality assurance and formatting
    
    Response Categories:
    - Tool-based responses: Incorporate database and calculation results
    - General responses: Advice and consultation without tool usage
    - Error recovery responses: User-friendly error communication
    - Mixed responses: Combination of tool results and general advice
    
    Input State:
    - tool_results: Results from executed tools (if any)
    - user_memo: User context and preferences
    - user_input: Original user request
    - routing_decision: Processing path taken
    
    Output State:
    - final_response: Complete formatted response for user
    - suggestions: Follow-up action recommendations
    - quick_replies: Quick response options for user convenience
    """
    
    touch_processing_timestamp(state)
    tool_results = state.get('tool_results', [])
    user_memo = state.get('user_memo', {})
    user_input = state.get('user_input', '')
    routing_decision = state.get('routing_decision', '')
    
    try:
        # Build context for response generation
        context_parts = []
        
        # Add user context
        profile = user_memo.get('profile', {})
        if profile:
            context_parts.append(f"ì‚¬ìš©ì í”„ë¡œí•„: {json.dumps(profile, ensure_ascii=False)}")
        
        successful_tools = [] 

        # Add tool results context
        if tool_results and isinstance(tool_results, dict):
            # ë”•ì…”ë„ˆë¦¬ì˜ ê°’(value)ë“¤ì„ ìˆœíšŒí•˜ë„ë¡ ìˆ˜ì •
            successful_tools = [res for tool, res in tool_results.items() if isinstance(res, dict) and res.get('success')]
            
            if successful_tools:
                tools_summary = []
                # tool_results ë”•ì…”ë„ˆë¦¬ë¥¼ ì˜¬ë°”ë¥´ê²Œ ìˆœíšŒ
                for tool_name, result_output in tool_results.items():
                    if isinstance(result_output, dict) and result_output.get('success'):
                        data = result_output.get('data', {})
                        if tool_name == 'db_query_tool':
                            count = data.get('total_count', 0)
                            tools_summary.append(f"ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰: {count}ê°œ ê²°ê³¼ ë°œê²¬")
                        elif tool_name == 'web_search_tool':
                            count = data.get('total_results', 0)
                            tools_summary.append(f"ì›¹ ê²€ìƒ‰: {count}ê°œ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘")
                        elif tool_name == 'calculator_tool':
                            result_val = data.get('result')
                            tools_summary.append(f"ê³„ì‚° ê²°ê³¼: {result_val}")
                        elif tool_name == 'user_db_update_tool':
                            update_details = data.get('update_details', [])
                            if update_details:
                                tools_summary.append(f"í”„ë¡œí•„ ì—…ë°ì´íŠ¸: {', '.join(update_details)}")
                
                if tools_summary:
                    context_parts.append("ì‹¤í–‰ëœ ì‘ì—…: " + ", ".join(tools_summary))
        
        # Create context string
        context_string = "\n\n".join(context_parts) if context_parts else "ì¼ë°˜ ìƒë‹´ ìš”ì²­"
        
        # Generate response using LLM
        messages = [
            {"role": "system", "content": RESPONSE_GENERATION_SYSTEM_PROMPT},
            {"role": "user", "content": f"""
ì‚¬ìš©ì ìš”ì²­: {user_input}
ì²˜ë¦¬ ê²½ë¡œ: {routing_decision}
ì»¨í…ìŠ¤íŠ¸: {context_string}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.
"""}
        ]
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
            max_tokens=1000
        )
        
        final_response = response.choices[0].message.content
        
        # Generate suggestions based on context
        suggestions = []
        if profile.get('wedding_date'):
            suggestions.append("D-day ê³„ì‚° ë° ì¤€ë¹„ ì¼ì • í™•ì¸í•˜ê¸°")
        if not profile.get('total_budget_manwon'):
            suggestions.append("ì˜ˆì‚° ì„¤ì • ë° í•­ëª©ë³„ ë¶„ë°° ê³„íší•˜ê¸°")
        if successful_tools:
            suggestions.append("ë” êµ¬ì²´ì ì¸ ì¡°ê±´ìœ¼ë¡œ ì¬ê²€ìƒ‰í•˜ê¸°")
        
        # Default suggestions if none generated
        if not suggestions:
            suggestions = [
                "ë‹¤ë¥¸ ì—…ì²´ ì¹´í…Œê³ ë¦¬ ì•Œì•„ë³´ê¸°",
                "ì˜ˆì‚° ê³„íš ìƒë‹´ë°›ê¸°", 
                "ì›¨ë”© ì¤€ë¹„ ì²´í¬ë¦¬ìŠ¤íŠ¸ í™•ì¸í•˜ê¸°"
            ]
        
        # Generate quick replies based on routing decision
        quick_replies = []
        if routing_decision == "recommendation":
            quick_replies = ["ë” ë§ì€ ì¶”ì²œ", "ë‹¤ë¥¸ ì§€ì—­ ë³´ê¸°", "ì˜ˆì‚°ëŒ€ ì¡°ì •"]
        elif routing_decision == "tool_execution":
            quick_replies = ["ê²°ê³¼ ìƒì„¸ë³´ê¸°", "ì¡°ê±´ ë³€ê²½í•˜ê¸°", "ì €ì¥í•˜ê¸°"]
        else:
            quick_replies = ["ì—…ì²´ ì¶”ì²œë°›ê¸°", "ì˜ˆì‚° ê³„ì‚°í•˜ê¸°", "ì¼ì • í™•ì¸í•˜ê¸°"]
        
        # Update state with generated response
        state['final_response'] = final_response
        state['suggestions'] = suggestions
        state['quick_replies'] = quick_replies
        state['status'] = "ok"
        
    except Exception as e:
        state['status'] = "error"
        state['reason'] = f"Response generation error: {str(e)}"
        # Fallback response
        state['final_response'] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        state['suggestions'] = ["ë‹¤ì‹œ ì§ˆë¬¸í•˜ê¸°", "ë„ì›€ë§ ë³´ê¸°"]
        state['quick_replies'] = ["ì¬ì‹œë„", "ë„ì›€ë§"]
        
    return state

# ============= ERROR HANDLING NODES =============

def error_handler_node(state: State) -> State:
    """
    Error Handler Node - Comprehensive Error Recovery System
    
    Purpose: Handle various error scenarios gracefully and provide user-friendly
    error messages with constructive recovery suggestions. This node ensures
    the system remains helpful even when technical issues occur.
    
    Key Functions:
    - Error categorization and user-friendly message generation
    - Recovery action suggestions based on error type
    - System health monitoring and reporting
    - Graceful degradation with fallback responses
    
    Error Categories:
    - Input validation errors: Guide users on proper input format
    - System connectivity issues: Explain temporary service interruptions
    - Data conflicts: Help resolve conflicting user information  
    - Tool execution failures: Suggest alternative approaches
    - Memory errors: Handle corrupted or missing user data
    
    Input State:
    - status: "error" status indicating error condition
    - reason: Technical error description
    - error_info: Additional error context and metadata
    
    Output State:
    - final_response: User-friendly error message with next steps
    - suggestions: Recovery actions and alternatives
    - status: "handled_error" to indicate successful error processing
    """
    
    touch_processing_timestamp(state)
    error_reason = state.get('reason', 'Unknown error occurred')
    error_info = state.get('error_info', {})
    user_input = state.get('user_input', '')
    
    try:
        # Generate user-friendly error response based on error type
        messages = [
            {"role": "system", "content": ERROR_HANDLER_SYSTEM_PROMPT},
            {"role": "user", "content": f"""
ì—ëŸ¬ ìƒí™©: {error_reason}
ì‚¬ìš©ì ìš”ì²­: {user_input}
ì¶”ê°€ ì •ë³´: {json.dumps(error_info, ensure_ascii=False)}

ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ì—ëŸ¬ ì‘ë‹µê³¼ í•´ê²° ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
"""}
        ]
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.3,
            max_tokens=500
        )
        
        error_response = response.choices[0].message.content
        
        # Generate recovery suggestions based on error type
        suggestions = []
        if "parsing" in error_reason.lower():
            suggestions = [
                "ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê¸°",
                "ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ ë‹¤ì‹œ ìš”ì²­í•˜ê¸°",
                "ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ì§ˆë¬¸í•˜ê¸°"
            ]
        elif "memory" in error_reason.lower() or "memo" in error_reason.lower():
            suggestions = [
                "ê¸°ë³¸ ì •ë³´ë¶€í„° ë‹¤ì‹œ ì„¤ì •í•˜ê¸°",
                "í”„ë¡œí•„ ì •ë³´ í™•ì¸í•˜ê¸°",
                "ìƒˆë¡œ ì‹œì‘í•˜ê¸°"
            ]
        elif "tool" in error_reason.lower() or "database" in error_reason.lower():
            suggestions = [
                "ì¡°ê±´ì„ ë‹¨ìˆœí™”í•´ì„œ ë‹¤ì‹œ ê²€ìƒ‰í•˜ê¸°",
                "ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì ‘ê·¼í•˜ê¸°",
                "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê¸°"
            ]
        else:
            suggestions = [
                "ë‹¤ì‹œ ì‹œë„í•˜ê¸°",
                "ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•˜ê¸°",
                "ê³ ê° ì§€ì›íŒ€ì— ë¬¸ì˜í•˜ê¸°"
            ]
        
        state['final_response'] = error_response
        state['suggestions'] = suggestions
        state['quick_replies'] = ["ë‹¤ì‹œ ì‹œë„", "ë„ì›€ë§", "ìƒˆë¡œ ì‹œì‘"]
        state['status'] = "handled_error"
        
    except Exception as e:
        # Ultimate fallback for error handler itself failing
        state['final_response'] = """ì£„ì†¡í•©ë‹ˆë‹¤. ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ê²°í˜¼ ì¤€ë¹„ì™€ ê´€ë ¨í•´ì„œ í•„ìš”í•œ ì •ë³´ë‚˜ ì¡°ì–¸ì€ ìµœëŒ€í•œ ì œê³µí•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”.

ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ê¶ê¸ˆí•˜ì‹œê±°ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹ ì§€ ë§ì”€í•´ ì£¼ì‹œë©´, ê°€ëŠ¥í•œ ë°©ë²•ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!"""
        
        state['suggestions'] = [
            "ì›¨ë”©í™€ ì¶”ì²œë°›ê¸°",
            "ì˜ˆì‚° ê³„íš ìƒë‹´ë°›ê¸°", 
            "ì›¨ë”© ì¤€ë¹„ ì²´í¬ë¦¬ìŠ¤íŠ¸ í™•ì¸í•˜ê¸°"
        ]
        state['quick_replies'] = ["ì›¨ë”©í™€", "ì˜ˆì‚°", "ì²´í¬ë¦¬ìŠ¤íŠ¸"]
        state['status'] = "handled_error"
        
    return state

# ============= NODE VALIDATION AND TESTING =============

def validate_all_nodes() -> Dict[str, bool]:
    """
    Validate that all required node functions are properly implemented
    and can handle basic state inputs without crashing.
    """
    
    from state import initialize_state
    
    test_state = initialize_state("test_user", "í…ŒìŠ¤íŠ¸ ì…ë ¥")
    
    nodes_to_test = {
        "parsing_node": parsing_node,
        "memo_check_node": memo_check_node,
        "conditional_router": conditional_router,
        "recommendation_node": recommendation_node,
        "tool_execution_node": tool_execution_node,
        "memo_update_node": memo_update_node,
        "response_generation_node": response_generation_node,
        "error_handler_node": error_handler_node
    }
    
    validation_results = {}
    
    for node_name, node_func in nodes_to_test.items():
        try:
            # Test with basic state
            result = node_func(test_state.copy())
            validation_results[node_name] = isinstance(result, dict) and 'status' in result
        except Exception as e:
            validation_results[node_name] = False
            print(f"âŒ {node_name} validation failed: {e}")
    
    return validation_results

# ============= MODULE EXPORTS =============

__all__ = [
    'parsing_node',
    'memo_check_node', 
    'conditional_router',
    'recommendation_node',
    'tool_execution_node',
    'memo_update_node',
    'response_generation_node',
    'error_handler_node',
    'validate_all_nodes'
]